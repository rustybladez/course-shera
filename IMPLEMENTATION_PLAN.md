# Course Shera - Detailed Implementation Plan
**Hackathon MVP Architecture & Execution Guide**

---

## ğŸ“‹ Executive Summary

Build an **AI-powered course supplementary learning platform** supporting:
- âœ… Content management (admin uploads PDFs/slides/code)
- âœ… Semantic search over materials (RAG + vector embeddings)
- âœ… AI generation (notes/slides/lab code with citations)
- âœ… Chat interface with context awareness
- âœ… Validation & quality checks
- ğŸ Bonus: handwritten OCR, video generation, community features

**Stack**: FastAPI (backend) + Next.js (frontend) + Neon Postgres + pgvector + Gemini API

**Timeline**: MVP in 2-3 days, polish & bonus features 1-2 days

---

## ğŸ—‚ï¸ Data Model (Postgres)

### Core Tables

```sql
-- Users & Roles
CREATE TABLE users (
  id UUID PRIMARY KEY,
  email VARCHAR UNIQUE,
  name VARCHAR,
  role ENUM('admin', 'student'),
  created_at TIMESTAMP DEFAULT NOW()
);

-- Courses
CREATE TABLE courses (
  id UUID PRIMARY KEY,
  code VARCHAR UNIQUE,        -- e.g., "CSE2200"
  title VARCHAR,
  term VARCHAR,               -- e.g., "Fall 2024"
  created_by UUID REFERENCES users,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Course materials (PDFs, slides, code files, notes)
CREATE TABLE materials (
  id UUID PRIMARY KEY,
  course_id UUID REFERENCES courses,
  category VARCHAR,           -- 'theory' | 'lab'
  title VARCHAR,
  type VARCHAR,               -- 'pdf' | 'slides' | 'code' | 'note' | 'link'
  storage_url VARCHAR,        -- local file path or URL
  week INT,                   -- which week of course
  topic VARCHAR,              -- e.g., "Functions and Scope"
  tags TEXT[],               -- searchable tags
  created_by UUID REFERENCES users,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Chunks of materials (with embeddings)
CREATE TABLE material_chunks (
  id UUID PRIMARY KEY,
  material_id UUID REFERENCES materials,
  chunk_index INT,
  text TEXT,                  -- actual content
  embedding VECTOR(768),      -- pgvector embedding
  language VARCHAR,           -- 'python' | 'javascript' | 'markdown' | NULL
  symbol_name VARCHAR,        -- for code: function/class name
  start_line INT,
  end_line INT,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Generated content (notes, slides, code generated by AI)
CREATE TABLE generated_assets (
  id UUID PRIMARY KEY,
  course_id UUID REFERENCES courses,
  request_type VARCHAR,        -- 'notes' | 'slides' | 'code' | 'pdf'
  prompt TEXT,                 -- original user request
  output_markdown TEXT,        -- markdown content
  output_url VARCHAR,          -- if rendered to PDF/HTML
  citations JSONB,             -- [{ chunk_id, material_id, excerpt }]
  validation_json JSONB,       -- { groundedness, relevance, clarity, hallucinations }
  created_by UUID REFERENCES users,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Chat conversations
CREATE TABLE chat_threads (
  id UUID PRIMARY KEY,
  course_id UUID REFERENCES courses,
  user_id UUID REFERENCES users,
  title VARCHAR,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Individual chat messages
CREATE TABLE chat_messages (
  id UUID PRIMARY KEY,
  thread_id UUID REFERENCES chat_threads,
  role VARCHAR,               -- 'user' | 'assistant'
  content TEXT,
  citations JSONB,            -- [{ chunk_id, material_id, excerpt }]
  metadata JSONB,             -- { tools_used: [...], model_version: ... }
  created_at TIMESTAMP DEFAULT NOW()
);

-- Bonus: Community posts
CREATE TABLE posts (
  id UUID PRIMARY KEY,
  course_id UUID REFERENCES courses,
  user_id UUID REFERENCES users,
  title VARCHAR,
  content TEXT,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE comments (
  id UUID PRIMARY KEY,
  post_id UUID REFERENCES posts,
  user_id UUID REFERENCES users,
  content TEXT,
  created_at TIMESTAMP DEFAULT NOW()
);
```

**Indexes for speed:**
```sql
CREATE INDEX idx_materials_course_id ON materials(course_id);
CREATE INDEX idx_chunks_material_id ON material_chunks(material_id);
CREATE INDEX idx_chunks_embedding ON material_chunks USING ivfflat (embedding vector_cosine_ops);
CREATE INDEX idx_chat_thread_id ON chat_messages(thread_id);
```

---

## ğŸ”Œ API Endpoints (FastAPI)

### Authentication (via Clerk)
- `GET /api/auth/me` â†’ current user profile
- `POST /api/auth/logout` â†’ invalidate session

### Materials (CMS)
- `GET /api/materials` â†’ list materials (filters: course_id, category, week, tags)
- `POST /api/materials` â†’ admin upload (title, file, metadata)
- `GET /api/materials/{id}` â†’ fetch material details
- `DELETE /api/materials/{id}` â†’ admin delete

### Ingestion (internal)
- `POST /api/ingest/{material_id}` â†’ trigger parsing + chunking + embedding
- `GET /api/ingest/{material_id}/status` â†’ check ingestion progress

### Search (Semantic RAG)
- `POST /api/search`
  - **Input**: `{ query: str, course_id?: uuid, filters?: { category?, week?, tags? } }`
  - **Output**: `{ results: [{ chunk_id, material_id, material_title, excerpt, similarity_score, metadata }], took_ms: int }`

### Generation (AI-powered)
- `POST /api/generate`
  - **Input**: `{ mode: 'notes|slides|code|pdf', prompt: str, course_id: uuid, reference_material_ids?: [uuid] }`
  - **Output**: `{ id: uuid, output_markdown: str, citations: [...], status: 'processing|completed|failed' }`
- `GET /api/generate/{id}` â†’ fetch result
- `GET /api/generate/{id}/status` â†’ polling status

### Validation
- `POST /api/validate`
  - **Input**: `{ asset_id: uuid }`
  - **Output**: `{ scores: { groundedness, relevance, clarity }, hallucinations: [...], fixes: [...] }`

### Chat (Conversational Agent)
- `GET /api/chat/threads` â†’ list user's chat threads
- `POST /api/chat/threads` â†’ create new thread
- `GET /api/chat/threads/{id}/messages` â†’ fetch thread messages
- `POST /api/chat/threads/{id}/message` â†’ send message (streaming response)
  - **Input**: `{ content: str }`
  - **Output**: stream of `{ role: 'assistant', content: str, citations: [...], tool_calls: [...] }`

### Bonus: Community
- `GET /api/community/posts` â†’ list posts (course_id)
- `POST /api/community/posts` â†’ create post
- `POST /api/community/posts/{id}/comments` â†’ add comment
- `POST /api/community/posts/{id}/bot-reply` â†’ (optional) auto-bot reply

---

## ğŸ§  Services (Business Logic)

### 1. **IngestService** (`backend/app/services/ingest.py`)
```python
class IngestService:
    def ingest_material(material_id: UUID) -> IngestStatus:
        # 1. Fetch material from storage
        # 2. Extract text (PDF/slides via PyMuPDF or python-docx)
        # 3. Parse code (detect language, optionally use tree-sitter)
        # 4. Chunk (heading-aware for theory, symbol-aware for code)
        # 5. Embed each chunk (Gemini embeddings API)
        # 6. Upsert to material_chunks table
        # 7. Update ingestion status
```

**Chunking strategies:**
- **Theory PDFs**: split on headings, target 400-800 tokens, 15% overlap
- **Code files**: split on functions/classes (use AST for Python), 200-500 tokens
- **Slides**: one chunk per slide

### 2. **SearchService** (`backend/app/services/search.py`)
```python
class SearchService:
    def semantic_search(query: str, course_id: UUID, filters: Dict) -> List[SearchResult]:
        # 1. Embed query (Gemini embeddings)
        # 2. Query pgvector: similarity_search(embedding, top_k=10)
        # 3. Filter by course_id, category, week, tags (optional)
        # 4. Rerank (optional: use Cohere or simple scorer)
        # 5. Return results with metadata
    
    def code_aware_search(query: str, course_id: UUID) -> List[SearchResult]:
        # For lab materials: also filter by language, symbol_name
        # Show snippets with line ranges
```

### 3. **GenerationService** (`backend/app/services/generation.py`)
```python
class GenerationService:
    def generate(mode: str, prompt: str, course_id: UUID) -> GeneratedAsset:
        # 1. Search for relevant materials (semantic_search)
        # 2. Format context: structured prompt with citations
        # 3. Call Gemini API with tool-calling (optional tools: search, wiki_lookup)
        # 4. Parse response: extract markdown, citations, etc.
        # 5. Validate output (see ValidationService)
        # 6. Save to DB with citations + validation report
    
    def generate_theory_notes(prompt, context_chunks):
        # Return: markdown with headings, bullets, key terms, citations
    
    def generate_slides(prompt, context_chunks):
        # Return: Markdown in Marp format (convert to PDF later if needed)
    
    def generate_lab_code(prompt, context_chunks, target_language='python'):
        # Return: runnable code + explanation + test template + citations
        # Ensure syntax is correct
```

### 4. **ValidationService** (`backend/app/services/validation.py`)
```python
class ValidationService:
    def validate_output(asset_id: UUID) -> ValidationReport:
        # 1. Fetch asset content + citations
        
        # 2. Deterministic checks:
        #    - All citations exist & are accurate
        #    - For code: syntax check (ast.parse, ruff)
        #    - For text: no major typos (optional)
        
        # 3. LLM rubric evaluation:
        #    - Ask Gemini to score: groundedness, relevance, clarity
        #    - Identify hallucinations: sentences not supported by citations
        #    - Suggest fixes
        
        # 4. Return: { scores, hallucinations, suggestions }
```

### 5. **ChatService** (`backend/app/services/chat.py`)
```python
class ChatService:
    def chat_message(thread_id: UUID, user_message: str) -> Message:
        # 1. Fetch thread history (last 5-10 messages for context)
        # 2. Call Gemini with system prompt + tools:
        #    - search(query, filters)
        #    - summarize(material_id)
        #    - generate(mode, prompt)
        #    - validate(asset_id)
        # 3. Execute tool calls (e.g., search if user asks "find notes on X")
        # 4. Collect citations from tool results
        # 5. Generate assistant response
        # 6. Save message to chat_messages with citations
        # 7. Stream or return response
```

---

## ğŸ¯ MVP Milestones

### **Milestone 1: Core Setup & Data Model** (Day 1 morning)
- [x] Remove Docker, configure Neon + local dev
- [x] Create database schema + migrations
- [ ] Implement Clerk auth integration
- [ ] Create Users table + profile management
- [ ] Test database connection end-to-end
- **Deliverable**: User signup/login working, database ready

### **Milestone 2: CMS & Material Upload** (Day 1 afternoon)
- [ ] Admin upload endpoint (title, file, metadata)
- [ ] Local file storage (save to `./storage/materials/`)
- [ ] Material listing/filtering endpoints
- [ ] Basic UI: admin upload page, material browser
- **Deliverable**: Admin can upload PDF/code/slides; students see list

### **Milestone 3: Ingestion & Vector Search** (Day 2 morning)
- [ ] IngestService: parse + chunk + embed
- [ ] Upsert chunks to `material_chunks` table
- [ ] SearchService: semantic search with pgvector
- [ ] Search UI: search bar + results with excerpts
- **Deliverable**: Students can search and get relevant results

### **Milestone 4: AI Generation (Theory + Lab)** (Day 2 afternoon)
- [ ] GenerationService: retrieve context + call Gemini
- [ ] Theory mode: generate notes (markdown with citations)
- [ ] Lab mode: generate code (Python, with explanation)
- [ ] UI: generator page with mode selector
- **Deliverable**: Can generate notes/code and see citations

### **Milestone 5: Validation & Quality** (Day 2 evening)
- [ ] ValidationService: syntax checks + LLM scoring
- [ ] Show validation report in UI
- **Deliverable**: Generated content has a quality badge/report

### **Milestone 6: Chat Agent** (Day 3 morning)
- [ ] ChatService with tools (search, generate, validate)
- [ ] Chat UI with message history + sources sidebar
- [ ] Stream responses (optional but nice)
- **Deliverable**: Can ask questions and get grounded answers

### **Bonus Features** (if time permits)
- [ ] Handwritten notes OCR (Mathpix or Google Vision)
- [ ] Content-to-video (Marp slides + TTS + basic stitching)
- [ ] Community posts + bot replies
- [ ] UI polish (gorgeous styling with Tailwind + shadcn)

---

## ğŸƒ Day-by-Day Execution Plan

### **Day 1**
- **Morning** (4 hours):
  - [x] Setup: Neon + environment + run scripts
  - [ ] Implement Clerk auth
  - [ ] Database schema creation
  - [ ] Test data seeding
  
- **Afternoon** (4 hours):
  - [ ] Admin upload endpoint + basic validation
  - [ ] Material CRUD endpoints
  - [ ] Storage integration (local files)
  - [ ] Material browser UI (Next.js)

### **Day 2**
- **Morning** (4 hours):
  - [ ] IngestService (parse + chunk + embed)
  - [ ] SearchService (pgvector + filtering)
  - [ ] Integrate Gemini embeddings API
  - [ ] Search UI + testing

- **Afternoon** (4 hours):
  - [ ] GenerationService (RAG pipeline)
  - [ ] Theory notes generation
  - [ ] Lab code generation
  - [ ] Generator UI

- **Evening** (2 hours):
  - [ ] ValidationService setup
  - [ ] Simple syntax checks for code

### **Day 3**
- **Morning** (4 hours):
  - [ ] ChatService with tools
  - [ ] Chat UI (Messages + sources sidebar)
  - [ ] Integration testing

- **Afternoon** (4 hours):
  - [ ] Polish: UI improvements, error handling
  - [ ] Add demo course + materials
  - [ ] Create video walkthrough / demo

- **Evening** (2 hours):
  - [ ] Bonus features if MVP is solid
  - [ ] Final testing + bug fixes

---

## ğŸ› ï¸ Implementation Notes

### File Organization
```
backend/app/
â”œâ”€â”€ api/routes/
â”‚   â”œâ”€â”€ auth.py          # Clerk integration
â”‚   â”œâ”€â”€ materials.py     # Upload, list, delete
â”‚   â”œâ”€â”€ ingest.py        # Trigger ingestion
â”‚   â”œâ”€â”€ search.py        # Semantic search
â”‚   â”œâ”€â”€ generate.py      # AI generation
â”‚   â”œâ”€â”€ validate.py      # Validation
â”‚   â””â”€â”€ chat.py          # Chat agent
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ingest.py        # Parsing + chunking + embedding
â”‚   â”œâ”€â”€ search.py        # Vector search
â”‚   â”œâ”€â”€ generation.py    # RAG + Gemini calls
â”‚   â”œâ”€â”€ validation.py    # Quality checks
â”‚   â””â”€â”€ chat.py          # Conversational agent
â”œâ”€â”€ models.py            # SQLAlchemy models
â”œâ”€â”€ schemas.py           # Pydantic request/response
â””â”€â”€ core/
    â””â”€â”€ config.py        # Settings
```

### Key Python Libraries
- **FastAPI**: routing, validation, OpenAPI docs
- **SQLAlchemy**: ORM + query builder
- **pgvector**: vector similarity search
- **google-genai**: Gemini API (chat, embeddings)
- **pymupdf**: PDF text extraction
- **python-docx**, **python-pptx**: Word/PowerPoint extraction

### Gemini Integration
```python
# For embeddings
from google.genai import Client
client = Client(api_key=settings.gemini_api_key)
embedding = client.embed_content(
    model="models/gemini-embedding-001",
    content=text
)

# For generation + tools
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=[...],
    tools=[
        {
            "name": "search_materials",
            "description": "Search course materials",
            "parameters": {...}
        }
    ]
)
```

### Frontend Components (Next.js + shadcn/ui)
- **Search Page**: input + filters + result cards with excerpts
- **Generator Page**: mode tabs (notes/slides/code) + prompt input + output markdown viewer
- **Chat Page**: message list + input + sources sidebar + citation highlights
- **Admin Upload**: file dropzone + metadata form + ingestion progress
- **Material Viewer**: display PDF/code with "Ask about this" button

---

## ğŸ Bonus: Quick Wins for Scoring

1. **Syntax-aware code search**: Filter by language, symbol name â†’ high "code quality" points
2. **Validation badge**: Show groundedness/relevance scores on generated content â†’ "reliability" points
3. **Citation highlights**: Click a citation to jump to source â†’ "explainability" points
4. **Handwritten OCR**: Upload image of notes â†’ auto-convert to Markdown â†’ "feature richness" points
5. **Beautiful UI**: Tailwind + shadcn/ui + dark mode â†’ "user experience" points
6. **Community bot**: Auto-reply to questions in discussion â†’ "engagement" points

---

## âš¡ Speed Optimization Tactics

1. **Precompute embeddings**: During upload, don't wait for embeddings async â†’ do it before showing success
2. **Cache search results**: Store recent searches in Redis (optional) or memory
3. **Use Gemini Flash**: Fast model for generation; use Pro only for complex tasks
4. **Mock data**: Pre-seed a sample course during setup so you can demo immediately
5. **Lazy load UI**: Don't load all materials at once; use pagination
6. **Background jobs**: Ingestion can be async (FastAPI background tasks) if it takes time

---

## ğŸ“Š Success Criteria (Hackathon Scoring)

âœ… **Core (MVP)**
- [ ] Users can upload materials (Admin)
- [ ] Users can search materials (Student)
- [ ] AI can generate content grounded in materials
- [ ] Chat is context-aware with citations
- [ ] Validation shows content quality

ğŸŒŸ **Bonus**
- [ ] Handwritten OCR
- [ ] Video generation
- [ ] Community features
- [ ] Beautiful UI
- [ ] Code syntax awareness

ğŸš€ **Pro Moves**
- [ ] Reranking (Cohere)
- [ ] Multi-language code support
- [ ] Live video streaming of generated content
- [ ] AI grading/feedback on student submissions

---

## ğŸ“š Reference Links

- **Neon Docs**: https://neon.tech/docs
- **FastAPI**: https://fastapi.tiangolo.com
- **SQLAlchemy**: https://docs.sqlalchemy.org
- **pgvector**: https://github.com/pgvector/pgvector
- **Gemini API**: https://ai.google.dev/docs
- **Next.js**: https://nextjs.org/docs
- **Clerk**: https://clerk.com/docs

Good luck! ğŸš€
